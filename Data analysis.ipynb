{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "import tweepy\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import unidecode\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# NLP stemmer and tokenizer definition\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load used CAs\n",
    "Andalusia = [\"Andalusia\", \"37.3399964,-4.5811614,250km\"]\n",
    "Madrid = [\"Madrid\", \"40.5248319,-3.7715628,60km\"]\n",
    "Catalonia = [\"Catalonia\", \"41.8523094,1.5745043,150km\"]\n",
    "Canary_Islands = [\"Canary_Islands\", \"28.5306525,-15.7464439,400km\"]\n",
    "Basque_Country = [\"Basque_Country\", \"42.9911816,-2.5543023,100km\"]\n",
    "\n",
    "# Other CAs\n",
    "#Extremadura = \n",
    "#CastillaLaMancha = \n",
    "#CastillaLeon = \n",
    "#Cantabria = \n",
    "#ComunidadValenciana = \n",
    "#Aragon = \n",
    "#LaRioja = \n",
    "#Navarra = \n",
    "#Asturias = \n",
    "#Murcia = \n",
    "\n",
    "CAS = [Andalusia, Madrid, Catalonia, Basque_Country, Canary_Islands]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tweets = pd.read_csv(\"tweet_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for CA in CAS:\n",
    "    new_sentence = \"\"\n",
    "    for index, row in df_tweets[df_tweets[\"location\"] == CA[0]].iterrows():\n",
    "        sentence = row[1].lower()\n",
    "        sentence = unidecode.unidecode(sentence)\n",
    "        words = sentence.split()\n",
    "        words = [w for w in words if not w in stopwords.words(\"spanish\")]\n",
    "        words = [w for w in words if (not \"@\" in w) if (\"rt\" != w.lower()) if (not \"http\" in w)]     # Delete words that contain mentions or the RT word \n",
    "        new_sentence = new_sentence + \" \".join(words)\n",
    "    tweet_group  =\"\".join(new_sentence)\n",
    "    tweet_group_wc = WordCloud().generate(tweet_group)\n",
    "    plt.figure()\n",
    "    plt.title(CA[0])\n",
    "    plt.imshow(tweet_group_wc)\n",
    "    plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for CA in CAS:\n",
    "    group_words = []\n",
    "    for index, row in df_tweets[df_tweets[\"location\"] == CA[0]].iterrows():\n",
    "        words = process_tweet(row[1])\n",
    "        group_words += words\n",
    "    count_words = Counter(group_words).most_common(10)\n",
    "    print(\"\\nFor {}:\".format(CA[0]))\n",
    "    print(count_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We see that most of the words are similar for each CA\n",
    "# What will have more weight in the classification will be the words for cities mentioned in the tweets\n",
    "# also the expressions typical of each place"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
